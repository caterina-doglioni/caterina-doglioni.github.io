---
---

@string{aps = {American Physical Society,}}

@article{aad2018search,
  title={Search for low-mass dijet resonances using trigger-level jets with the ATLAS detector in pp collisions at $\sqrt{s}=13$ TeV},
  author={Aad, G. and others},
  collaboration={ATLAS Collaboration},
  journal={Phys. Rev. Lett.},
  volume={121},
  pages={081801},
  year={2018},
  eprint={1804.03496},
  archivePrefix={arXiv},
  primaryClass={hep-ex},
  selected={true},
  abstract={This paper describes the first search using the Trigger Level Analysis technique in ATLAS with the 2016 LHC dataset, with constraints on Dark Matter mediator particles decaying into dijets.  I worked on the core software to make recording on this data possible, and a postdoc in my group (Will Kalderon) was the contact editor for the analysis. <br><b>Abstract:</b> Searches for dijet resonances with sub-TeV masses using the ATLAS detector at the Large Hadron Collider can be statistically limited by the bandwidth available to inclusive single-jet triggers, whose data-collection rates at low transverse momentum are much lower than the rate from Standard Model multijet production. This Letter describes a new search for dijet resonances where this limitation is overcome by recording only the event information calculated by the jet trigger algorithms, thereby allowing much higher event rates with reduced storage needs. The search targets low-mass dijet resonances in the range 450-1800 GeV. The analyzed dataset has an integrated luminosity of up to 29.3 fb$^{-1}$ and was recorded at a center-of-mass energy of 13 TeV. No excesses are found; limits are set on Gaussian-shaped contributions to the dijet mass distribution from new particles and on a model of dark-matter particles with axial-vector couplings to quarks.},
  url={https://link.aps.org/doi/10.1103/PhysRevLett.121.081801},
  bibtex_show={true}
}

@article{aad2025search,
  title={Search for electroweak-scale dijet resonances using trigger-level analysis with the ATLAS detector in 132 fb$^{-1}$ of pp collisions at $\sqrt{s}=13$ TeV},
  author={Aad, G. and others},
  collaboration={ATLAS Collaboration},
  journal={Phys. Rev. D},
  volume={112},
  pages={092015},
  year={2025},
  eprint={2509.01219},
  archivePrefix={arXiv},
  primaryClass={hep-ex},
  abstract={This paper extends and improves the first TLA search for dark matter mediators with the full Run-2 dataset and applies robust statistical analysis techniques capable of coping with the largest background sample recorded at the LHC. It sets constraints on Dark Matter mediator particles decaying into dijets. I worked on the core software for the real-time stream together with my collaborators at Ohio State University (Marco Montella) and Humboldt University Berlin (Teng Jian Khoo), and a postdoc in my group (Tobias Fitschen) was the contact editor for the analysis.<br><b>Abstract:</b> This article reports on a search for dijet resonances using $132$ fb$^{-1}$ of $pp$ collision data recorded at $\sqrt{s} = 13$ TeV by the ATLAS detector at the Large Hadron Collider. The search is performed solely on jets reconstructed within the ATLAS trigger to overcome bandwidth limitations imposed on conventional single-jet triggers, which would otherwise reject data from decays of sub-TeV dijet resonances. Collision events with two jets satisfying transverse momentum thresholds of $p_{\textrm{T}} \ge 85$ GeV and jet rapidity separation of $|y^{*}|<0.6$ are analysed for dijet resonances with invariant masses from $375$ to $1800$ GeV. A data-driven background estimate is used to model the dijet mass distribution from multijet processes. No significant excess above the expected background is observed. Upper limits are set at $95\%$ confidence level on coupling values for a benchmark leptophobic axial-vector $Z^{\prime}$ model and on the production cross-section for a new resonance contributing a Gaussian-distributed line-shape to the dijet mass distribution.},
  bibtex_show={true}
}

@article{aad2013jet,
  title={Jet energy measurement with the ATLAS detector in proton-proton collisions at $\sqrt{s}=7$ TeV},
  author={Aad, G. and others},
  collaboration={ATLAS Collaboration},
  journal={Eur. Phys. J. C},
  volume={73},
  pages={2304},
  year={2013},
  eprint={1112.6426},
  archivePrefix={arXiv},
  primaryClass={hep-ex},
  abstract={This paper documents the calibration and performance of hadronic jets in the ATLAS detector for the full 2010 LHC dataset, shortly after the LHC turned on. This was my thesis topic, and I have been the author of the analysis and public notes that appear in sections 8-9.<br><b>Abstract:</b> The jet energy scale (JES) and its systematic uncertainty are determined for jets measured with the ATLAS detector at the LHC in proton-proton collision data at a centre-of-mass energy of sqrt(s) = 7 TeV corresponding to an integrated luminosity of 38 inverse pb. Jets are reconstructed with the anti-kt algorithm with distance parameters R=0.4 or R=0.6. Jet energy and angle corrections are determined from Monte Carlo simulations to calibrate jets with transverse momenta pt > 20 GeV and pseudorapidities eta<4.5. The JES systematic uncertainty is estimated using the single isolated hadron response measured in situ and in test-beams.},
  bibtex_show={true}
}

@article{buchmueller2017search,
  title={Search for dark matter at colliders},
  author={Buchmueller, Oliver and Doglioni, Caterina and Wang, Lian-Tao},
  journal={Nature Physics},
  volume={13},
  pages={217--223},
  year={2017},
  eprint={1912.12739},
  archivePrefix={arXiv},
  primaryClass={hep-ph},
  abstract={This article reviews the state of dark matter theory and WIMP searches at the Large Hadron Collider. We were invited by the journal for a special issue of Nature Physics and Nature Astronomy, focused on dark matter.<br><b>Abstract:</b> Multiple astrophysical and cosmological observations show that the majority of the matter in the universe is non-luminous. It is not made of known particles, and it is called dark matter. This is one of the few pieces of concrete experimental evidence of new physics beyond the Standard Model. Despite decades of effort, we still know very little about the identity of dark matter; it remains one of the biggest outstanding mysteries facing particle physics. Among the numerous proposals to explain its nature, the Weakly Interacting Massive Particle (WIMP) scenario stands out. The WIMP scenario is based on a simple assumption that dark matter is in thermal equilibrium in the early hot universe, and that the dark matter particles have mass and interactions not too different from the massive particles in the Standard Model. Testing the WIMP hypothesis is a focus for many experimental searches. A variety of techniques are employed including the observation of WIMP annihilation, the measurement of WIMP-nucleon scattering in terrestrial detectors, and the inference of WIMP production at high energy colliders. In this article, we will focus on the last approach, and in particular on WIMP dark matter searches at the Large Hadron Collider.},
  bibtex_show={true}
}

@article{boveia2018dark,
  title={Dark Matter Searches at colliders},
  author={Boveia, Antonio and Doglioni, Caterina},
  journal={Ann. Rev. Nucl. Part. Sci.},
  volume={68},
  pages={429--459},
  year={2018},
  eprint={1810.12238},
  archivePrefix={arXiv},
  primaryClass={hep-ex},
  abstract={This is an invited review of dark matter searches at colliders, targeting a broad range of audiences (from PhD students to experts in the field), It describes the state of the art of collider searches for dark matter, their connections to other experiments and an outlook for the future.<br><b>Abstract:</b> Colliders, among the most successful tools of particle physics, have revealed much about matter. This review describes how colliders contribute to the search for particle dark matter, focusing on the highest-energy collider currently in operation, the Large Hadron Collider (LHC) at CERN. In the absence of hints about the character of interactions between dark matter and standard matter, this review emphasizes what could be observed in the near future, presents the main experimental challenges, and discusses how collider searches fit into the broader field of dark matter searches. Finally, it highlights a few areas to watch for the future LHC program.},
  bibtex_show={true}
}

@incollection{streitbianchi2022dark,
  title={Dark matter at ATLAS},
  author={Doglioni, Caterina and others},
  booktitle={Advances in cosmology},
  editor={Streit-Bianchi, M. and others},
  pages={398},
  year={2022},
  publisher={Springer},
  abstract={Initially written as an ATLAS Feature, this review represents the ATLAS experiment in a collection of expert articles outlining the latest research on modern cosmology and related topics in a multi-disciplinary approach.<br><b>Abstract:</b> Recent advances in cosmology encompass a wide range of topics, from the universe's origins and evolution to cutting-edge research on dark matter, dark energy, and cosmic microwave background radiation. The field emphasizes multidisciplinary approaches and technologies to explore the unknown, integrating experimental results with philosophical thinking and artistic representation.},
  bibtex_show={true}
}

@article{abercrombie2015dark,
  title={Dark Matter Benchmark Models for Early LHC Run-2 Searches: Report of the ATLAS/CMS Dark Matter Forum},
  author={Abercrombie, A. and others},
  journal={Phys. Dark Univ.},
  volume={26},
  pages={100371},
  year={2019},
  eprint={1507.00966},
  archivePrefix={arXiv},
  primaryClass={hep-ex},
  abstract={As one of the Dark Matter Forum and Working Group organisers from 2014-2018, I have been among the editors for the four publications, published on Physics of the Dark Universe. This document is the final report of the Dark Matter Forum and contains DM signal benchmarks for most of the LHC Run-2 and Run-3 searches so far, as well as studies of their parameter space, and a repository of generator implementation as supplementary material. <br><b>Abstract:</b> This document is the final report of the ATLAS-CMS Dark Matter Forum, a forum organized by the ATLAS and CMS collaborations with the participation of experts on theories of Dark Matter, to select a minimal basis set of dark matter simplified models that should support the design of the early LHC Run-2 searches. A prioritized, compact set of benchmark models is proposed, accompanied by studies of the parameter space of these models and a repository of generator implementations. This report also addresses how to apply the Effective Field Theory formalism for collider searches and present the results of such interpretations.},
  bibtex_show={true}
}

@article{boveia2025snowmass,
  title={Snowmass 2021 cross frontier report: Dark matter complementarity},
  author={Boveia, A. and others},
  journal={SciPost Phys. Comm. Rep.},
  volume={7},
  year={2025},
  abstract={Together with the other conveners of all Topical Groups for DM in the Snowmass process, we advocate for a unified global strategy to maximize DM discovery through a diverse portfolio of complementary experiments and open data sharing. <br><b>Abstract:</b> The fundamental nature of Dark Matter is a central theme of the Snowmass 2021 process, extending across all frontiers. Over the past decade, advancements in detector technology, analysis techniques, and theoretical modeling have led to a new generation of experiments and searches, broadening the types of dark matter candidates that can be pursued. The report emphasizes the significant potential for discoveries in the coming decade that could transform our understanding of dark matter.},
  bibtex_show={true}
}

@article{gupta2025boa,
  title={BOA Constrictor: A Mamba-based lossless compressor for High Energy Physics data},
  author={Gupta, A. and Elliott, T. and Doglioni, C.},
  journal={arXiv preprint},
  year={2025},
  eprint={2511.11337},
  archivePrefix={arXiv},
  primaryClass={physics.data-an},
  abstract={In this paper we describe the early prototype of ”BOA Constrictor”, a novel, streaming-capable lossless compressor based on the Mamba state space ML model, which achieves state-of-the-art compression ratios on HEP datasets and  outperforms traditional algorithms used for LHC data.<br><b>Abstract:</b> The petabyte-scale data generated annually by High Energy Physics (HEP) experiments like those at the Large Hadron Collider present a significant data storage challenge. Whilst traditional algorithms like LZMA and ZLIB are widely used, they often fail to exploit the deep structure inherent in scientific data. We investigate the application of modern state space models (SSMs) to this problem, which have shown promise for capturing long-range dependencies in sequences. We present the Bytewise Online Autoregressive (BOA) Constrictor, a novel, streaming-capable lossless compressor built upon the Mamba architecture. BOA combines an autoregressive Mamba model for next-byte prediction with a parallelised streaming range coder. We evaluate our method on three distinct structured datasets in HEP, demonstrating state-of-the-art compression ratios, improving upon LZMA-9 across all datasets. These improvements range from 2.21$\times$ (vs. 1.69$\times$) on the ATLAS dataset to a substantial 44.14$\times$ (vs. 27.14$\times$) on the highly-structured CMS dataset, with a modest $\sim 4.5$MB model size. However, this gain in compression ratio comes with a trade-off in throughput; the Storage-Saving Rate ($\sigma_{SSR}$) of our prototype currently lags behind highly-optimised CPU-based algorithms like ZLIB.},
  bibtex_show={true}
}

@article{alves2017roadmap,
  title={A roadmap for HEP software and computing R&D for the 2020s},
  author={Alves Jr, A. and others},
  collaboration={HEP Software Foundation},
  journal={Comput. Softw. Big Sci.},
  volume={3},
  number={1},
  pages={7},
  year={2019},
  eprint={1712.06982},
  archivePrefix={arXiv},
  primaryClass={physics.comp-ph},
  abstract={This whitepaper delineates the R&D activities needed to prepare for the upgrades of the experimental programme of HEP in the coming decades. I have contributed to the main document and chapter on trigger and event reconstruction in terms of real-time analysis. <br><b>Abstract:</b> Particle physics has an ambitious and broad experimental programme for the coming decades. This programme requires large investments in detector hardware, either to build new facilities and experiments, or to upgrade existing ones. Similarly, it requires commensurate investment in the R&D of software to acquire, manage, process, and analyse the shear amounts of data to be recorded. In planning for the HL-LHC in particular, it is critical that all of the collaborating stakeholders agree on the software goals and priorities, and that the efforts complement each other. In this spirit, this white paper describes the R&D activities required to prepare for this software upgrade.},
  bibtex_show={true}
}
